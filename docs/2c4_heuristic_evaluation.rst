Heuristic Evaluation
====================

This section contains results of the Heuristic Evaluation exercise conducted for the currently existing version of the Open Data Portal (opendata.klldev.org)


The evaluation exercise is intended to identify and assess problems with the existing user interface. It is hoped that learnings from the user sense-making exercise will pave way for a thorough heuristic evaluation of the currently existing portal across the following three dimensions:

1. **Learnability**
^^^^^^^^^^^^^^^^^^^
This refers to an assessment of how easy or difficult it is for identified user groups to learn how to use the system. In our assessment, we have assessed the learnability of currently existing UI along the following dimensions:

a. **Information Scent**: This refers to whether the UI element in question has appropriate cues that gives the user more context. For e.g. for a specific search result, search engines often display additional information such as a snippet from the link, the site's domain name etc. which gives the user more context into what he achieves on clicking the link.

b. **Affordances and their appropriateness**: This refers 'to the perceived and actual properties of a thing, primarily the properties that determine how the thing could be operated.' It is very important that affordances made available by UI elements behave in the way user expect them to behave. For instance, a user expects a button to perform an action, or a dropdown menu to present the user with more options on click. These are examples of affordances being in line with the users' expectations.

  On the other hand, there may be instances when the affordances offered by a UI element does not behave in line with how the user expects them to. For example, refer to the image below, where users may/may not immediately infer that the picture on the right, is in fact, a clickable link.

  .. image:: _data/affordance.png

c. **Metaphors**: Does the UI element have a metaphor, i.e an analog counterpart in the real world. If yes, how far does the UI element deviate from its analog counterpart w.r.t. the interactions it provides.

d. **Feedback**: This simply refers to the UI's response when a user interacts with it. In other words, is it apparent what is happening/what is going to happen as soon as the user clicks something?

e. **Visibility of navigation state**: Does the user know what part of the app he is currently viewing, is he aware of all other options?

f. **Visibility of view state**: Is the user aware of all the changes in the present view that may happen if he interacts with the UI?

g. **Locus of attention**: Are user controls present within the user's locus of attention, i.e. the visual space wherein the user's attention happens to be?

h. **Perceptual fusion**: This simply refers to whether the UI responds to user action within an appropriate response time.

i. **Internal consistency**: Are UI elements present in this section consistent with other parts of the application?

j. **External consistency**: Are UI elements present in the application consistent with what users use in other applications?


**Efficiency**
^^^^^^^^^^^^^^

This refers to an assessment of how quickly a user can arrive at what he wants from the system:

  - Is it easy to move to different pages, different areas of pages and different states of the application?
  - How much difference in time does it take for an experienced user to arrive at what is required as opposed to an inexperienced user?
  - Are there automated actions running behind to reduce the users cognitive load, letting the user work just on high level tasks? Are they required for this platform?

3. **Safety**: This refers to an assessment of error prone areas of the interface. Things like, but not limited to:

  - Do errors have a consistent behavior?
  - Does the user always know when anything unexpected or unusual happens?
  - Are there appropriate messages or dialog boxes?
  - Are suggestions and errors in plain language?
